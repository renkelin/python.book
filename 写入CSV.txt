import csv
import requests
from bs4 import BeautifulSoup

# 函数封装
# def douban_top250_spider():
start_url = 'https://book.douban.com/top250'

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.164 Safari/537.36 Edg/91.0.864.71'
}

for i in range(3):
    params = {
        'start': str(i * 25)
}
    res = requests.get(url=start_url, headers=headers, params=params)
    bs_data = BeautifulSoup(res.text, 'html.parser')
    datas = bs_data.find_all('tr', class_='item')
    for book in datas:
        book_name = book.find('div', class_='pl2').find('a').text.replace("\n", "").replace(" ", "")
        # book_name = book.find_all('a')[1]['title']

        author = book.find('p', class_='pl').text
        rating = book.find('span', class_='rating_nums').text
        # print(book_name, rating, author)

        with open('douban_top250.csv', 'a', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow([book_name, rating, author])

# douban_top250_spider()